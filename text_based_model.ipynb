{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset:\n",
      "Index(['Dialogue_ID', 'Utterance_ID', 'Emotion', 'Word_Count', 'Char_Count',\n",
      "       'Sentiment_Polarity', 'Audio_Duration', 'MFCCs'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv(r'datasets\\processed\\meld_features.csv')\n",
    "\n",
    "# Display column names\n",
    "print(\"Columns in the dataset:\")\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the raw dataset:\n",
      "Index(['Sr No.', 'Utterance', 'Speaker', 'Emotion', 'Sentiment', 'Dialogue_ID',\n",
      "       'Utterance_ID', 'Season', 'Episode', 'StartTime', 'EndTime'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load raw train, dev, or test dataset to check columns\n",
    "raw_data_path = r'datasets\\raw\\MELD\\train\\train_sent_emo.csv'\n",
    "raw_data = pd.read_csv(raw_data_path)\n",
    "\n",
    "# Display column names\n",
    "print(\"Columns in the raw dataset:\")\n",
    "print(raw_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in merged dataset:\n",
      "Index(['Dialogue_ID', 'Utterance_ID', 'Emotion', 'Word_Count', 'Char_Count',\n",
      "       'Sentiment_Polarity', 'Audio_Duration', 'MFCCs', 'Utterance'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rajt8\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rajt8\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset updated with 'Clean_Utterance' column and saved to datasets\\processed\\meld_features_updated.csv\n"
     ]
    }
   ],
   "source": [
    "# Load processed and raw datasets\n",
    "processed_path = r'datasets\\processed\\meld_features.csv'\n",
    "raw_train_path = r'datasets\\raw\\MELD\\train\\train_sent_emo.csv'\n",
    "\n",
    "processed_data = pd.read_csv(processed_path)\n",
    "raw_data = pd.read_csv(raw_train_path)\n",
    "\n",
    "# Merge raw and processed datasets to restore 'Utterance'\n",
    "merged_data = pd.merge(\n",
    "    processed_data,\n",
    "    raw_data[['Dialogue_ID', 'Utterance_ID', 'Utterance']],\n",
    "    on=['Dialogue_ID', 'Utterance_ID'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Check for successful merge\n",
    "print(\"Columns in merged dataset:\")\n",
    "print(merged_data.columns)\n",
    "\n",
    "# Define text preprocessing function\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word not in stop_words and word not in punctuation]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Compute 'Clean_Utterance'\n",
    "merged_data['Clean_Utterance'] = merged_data['Utterance'].apply(preprocess_text)\n",
    "\n",
    "# Save updated dataset\n",
    "updated_path = r'datasets\\processed\\meld_features_updated.csv'\n",
    "merged_data.to_csv(updated_path, index=False)\n",
    "\n",
    "print(f\"Dataset updated with 'Clean_Utterance' column and saved to {updated_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 8287\n",
      "Validation set size: 1776\n",
      "Test set size: 1776\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the updated dataset\n",
    "data = pd.read_csv(r'datasets\\processed\\meld_features_updated.csv')\n",
    "\n",
    "# Split text and labels\n",
    "X_train_text, X_temp, y_train, y_temp = train_test_split(\n",
    "    data['Clean_Utterance'], data['Emotion'], test_size=0.3, stratify=data['Emotion'], random_state=42)\n",
    "X_val_text, X_test_text, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "# Display dataset sizes\n",
    "print(f\"Training set size: {len(X_train_text)}\")\n",
    "print(f\"Validation set size: {len(X_val_text)}\")\n",
    "print(f\"Test set size: {len(X_test_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in Clean_Utterance: 91\n",
      "Training set size: 8287\n",
      "Validation set size: 1776\n",
      "Test set size: 1776\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in Clean_Utterance\n",
    "print(f\"Missing values in Clean_Utterance: {data['Clean_Utterance'].isna().sum()}\")\n",
    "\n",
    "# Fill missing values with empty strings\n",
    "data['Clean_Utterance'] = data['Clean_Utterance'].fillna('')\n",
    "\n",
    "# Split text and labels again\n",
    "X_train_text, X_temp, y_train, y_temp = train_test_split(\n",
    "    data['Clean_Utterance'], data['Emotion'], test_size=0.3, stratify=data['Emotion'], random_state=42)\n",
    "X_val_text, X_test_text, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "# Display updated sizes\n",
    "print(f\"Training set size: {len(X_train_text)}\")\n",
    "print(f\"Validation set size: {len(X_val_text)}\")\n",
    "print(f\"Test set size: {len(X_test_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF vectorization complete. Number of features: 4515\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000) \n",
    "\n",
    "# Fit and transform the training text\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_text)\n",
    "\n",
    "# Transform validation and test text\n",
    "X_val_tfidf = tfidf.transform(X_val_text)\n",
    "X_test_tfidf = tfidf.transform(X_test_text)\n",
    "\n",
    "print(f\"TF-IDF vectorization complete. Number of features: {X_train_tfidf.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.29      0.05      0.08       205\n",
      "     disgust       0.33      0.02      0.04        49\n",
      "        fear       0.00      0.00      0.00        48\n",
      "         joy       0.53      0.18      0.27       308\n",
      "     neutral       0.51      0.94      0.66       840\n",
      "     sadness       0.41      0.05      0.10       130\n",
      "    surprise       0.55      0.16      0.25       196\n",
      "\n",
      "    accuracy                           0.51      1776\n",
      "   macro avg       0.37      0.20      0.20      1776\n",
      "weighted avg       0.47      0.51      0.40      1776\n",
      "\n",
      "Validation Accuracy: 0.5051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rajt8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\rajt8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\rajt8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize and train Logistic Regression model\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = model.predict(X_val_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nLogistic Regression Validation Results:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression with Class Weights Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.14      0.20      0.16       205\n",
      "     disgust       0.06      0.16      0.08        49\n",
      "        fear       0.07      0.29      0.12        48\n",
      "         joy       0.33      0.35      0.34       308\n",
      "     neutral       0.62      0.31      0.41       840\n",
      "     sadness       0.14      0.23      0.17       130\n",
      "    surprise       0.33      0.33      0.33       196\n",
      "\n",
      "    accuracy                           0.30      1776\n",
      "   macro avg       0.24      0.27      0.23      1776\n",
      "weighted avg       0.42      0.30      0.33      1776\n",
      "\n",
      "Validation Accuracy: 0.2956\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train Logistic Regression with balanced class weights\n",
    "model_weighted = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
    "model_weighted.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_weighted = model_weighted.predict(X_val_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nLogistic Regression with Class Weights Validation Results:\")\n",
    "print(classification_report(y_val, y_val_pred_weighted))\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred_weighted):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\rajt8\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\rajt8\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.26.2)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\rajt8\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\rajt8\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\rajt8\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\rajt8\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\rajt8\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (3.2.0)\n",
      "Name: imbalanced-learn\n",
      "Version: 0.13.0\n",
      "Summary: Toolbox for imbalanced dataset in machine learning\n",
      "Home-page: https://imbalanced-learn.org/\n",
      "Author: \n",
      "Author-email: \"G. Lemaitre\" <g.lemaitre58@gmail.com>, \"C. Aridas\" <ichkoar@gmail.com>\n",
      "License: \n",
      "Location: C:\\Users\\rajt8\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\n",
      "Requires: joblib, numpy, scikit-learn, scipy, sklearn-compat, threadpoolctl\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn --user\n",
    "!pip show imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data after SMOTE - Samples: 27426\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to training data\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "print(f\"Training data after SMOTE - Samples: {X_train_resampled.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression with SMOTE Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.17      0.20      0.18       205\n",
      "     disgust       0.05      0.14      0.08        49\n",
      "        fear       0.06      0.23      0.09        48\n",
      "         joy       0.32      0.32      0.32       308\n",
      "     neutral       0.57      0.34      0.43       840\n",
      "     sadness       0.13      0.18      0.15       130\n",
      "    surprise       0.31      0.32      0.31       196\n",
      "\n",
      "    accuracy                           0.30      1776\n",
      "   macro avg       0.23      0.25      0.22      1776\n",
      "weighted avg       0.39      0.30      0.33      1776\n",
      "\n",
      "Validation Accuracy: 0.2979\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression on resampled data\n",
    "model_smote = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model_smote.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_smote = model_smote.predict(X_val_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(\"\\nLogistic Regression with SMOTE Validation Results:\")\n",
    "print(classification_report(y_val, y_val_pred_smote))\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred_smote):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.18      0.18      0.18       205\n",
      "     disgust       0.05      0.06      0.05        49\n",
      "        fear       0.06      0.23      0.10        48\n",
      "         joy       0.29      0.25      0.27       308\n",
      "     neutral       0.53      0.43      0.48       840\n",
      "     sadness       0.12      0.14      0.13       130\n",
      "    surprise       0.21      0.26      0.23       196\n",
      "\n",
      "    accuracy                           0.32      1776\n",
      "   macro avg       0.21      0.22      0.21      1776\n",
      "weighted avg       0.36      0.32      0.33      1776\n",
      "\n",
      "Validation Accuracy: 0.3153\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Train Random Forest on resampled data\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_rf = rf_model.predict(X_val_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nRandom Forest Validation Results:\")\n",
    "print(classification_report(y_val, y_val_pred_rf))\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred_rf):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.15      0.20      0.18       205\n",
      "     disgust       0.05      0.10      0.07        49\n",
      "        fear       0.06      0.25      0.10        48\n",
      "         joy       0.33      0.34      0.33       308\n",
      "     neutral       0.56      0.35      0.44       840\n",
      "     sadness       0.16      0.22      0.18       130\n",
      "    surprise       0.32      0.28      0.30       196\n",
      "\n",
      "    accuracy                           0.31      1776\n",
      "   macro avg       0.23      0.25      0.23      1776\n",
      "weighted avg       0.39      0.31      0.33      1776\n",
      "\n",
      "Validation Accuracy: 0.3069\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Train SVM on resampled data\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_svm = svm_model.predict(X_val_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nSVM Validation Results:\")\n",
    "print(classification_report(y_val, y_val_pred_svm))\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred_svm):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF with N-grams complete. Number of features: 5000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF with N-grams (unigrams, bigrams, trigrams)\n",
    "tfidf_ngram = TfidfVectorizer(max_features=5000, ngram_range=(1, 3))  \n",
    "\n",
    "# Fit and transform the training text\n",
    "X_train_tfidf_ngram = tfidf_ngram.fit_transform(X_train_text)\n",
    "\n",
    "# Transform validation and test text\n",
    "X_val_tfidf_ngram = tfidf_ngram.transform(X_val_text)\n",
    "X_test_tfidf_ngram = tfidf_ngram.transform(X_test_text)\n",
    "\n",
    "print(f\"TF-IDF with N-grams complete. Number of features: {X_train_tfidf_ngram.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest with N-grams Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.11      0.05      0.07       205\n",
      "     disgust       0.13      0.04      0.06        49\n",
      "        fear       0.13      0.04      0.06        48\n",
      "         joy       0.32      0.17      0.22       308\n",
      "     neutral       0.51      0.78      0.62       840\n",
      "     sadness       0.23      0.10      0.14       130\n",
      "    surprise       0.33      0.23      0.27       196\n",
      "\n",
      "    accuracy                           0.44      1776\n",
      "   macro avg       0.25      0.20      0.21      1776\n",
      "weighted avg       0.37      0.44      0.38      1776\n",
      "\n",
      "Validation Accuracy: 0.4392\n"
     ]
    }
   ],
   "source": [
    "# Retrain Random Forest on n-gram features\n",
    "rf_model_ngram = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf_model_ngram.fit(X_train_tfidf_ngram, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_rf_ngram = rf_model_ngram.predict(X_val_tfidf_ngram)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(\"\\nRandom Forest with N-grams Validation Results:\")\n",
    "print(classification_report(y_val, y_val_pred_rf_ngram))\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred_rf_ngram):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need More work on this !!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
