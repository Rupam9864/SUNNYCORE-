{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text preprocessing unit test passed!\n",
      "Audio feature extraction unit test passed!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Load the processed dataset\n",
    "data_path = 'datasets/processed/meld_features_updated.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Function to test text preprocessing\n",
    "def test_text_preprocessing():\n",
    "    sample_text = \"Hello! How are you doing today?\"\n",
    "    tokenized_text = word_tokenize(sample_text.lower())\n",
    "    assert len(tokenized_text) > 0, \"Tokenization failed!\"\n",
    "    assert \"hello\" in tokenized_text, \"Lowercasing failed!\"\n",
    "    print(\"Text preprocessing unit test passed!\")\n",
    "\n",
    "# Function to test audio feature extraction\n",
    "def test_audio_feature_extraction(audio_path):\n",
    "    try:\n",
    "        audio, sr = librosa.load(audio_path, sr=16000)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "        assert mfccs.shape[0] == 13, \"MFCC extraction failed!\"\n",
    "        print(\"Audio feature extraction unit test passed!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Audio feature extraction test failed: {e}\")\n",
    "\n",
    "# Run tests\n",
    "test_text_preprocessing()\n",
    "sample_audio_file = 'datasets/raw/MELD/train/audio/dia0_utt0.wav'\n",
    "test_audio_feature_extraction(sample_audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " Dialogue_ID           0\n",
      "Utterance_ID          0\n",
      "Emotion               0\n",
      "Word_Count            0\n",
      "Char_Count            0\n",
      "Sentiment_Polarity    0\n",
      "Audio_Duration        0\n",
      "MFCCs                 0\n",
      "Utterance             0\n",
      "Clean_Utterance       0\n",
      "Audio_Path            0\n",
      "dtype: int64\n",
      "Number of duplicate rows: 0\n",
      "Number of missing audio files: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values)\n",
    "\n",
    "# Check for duplicate entries\n",
    "duplicates = data.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "# Ensure all audio files exist\n",
    "import os\n",
    "\n",
    "audio_files_missing = []\n",
    "for path in data['Audio_Path']:\n",
    "    if not os.path.exists(path):\n",
    "        audio_files_missing.append(path)\n",
    "\n",
    "print(f\"Number of missing audio files: {len(audio_files_missing)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled data for manual inspection:\n",
      "       Emotion                                          Utterance  \\\n",
      "3615   sadness                                    Looks good, uh?   \n",
      "5105     anger  Hey, thats never gonna make it all the way ov...   \n",
      "4270     anger       We found your fire alarm in the trash chute.   \n",
      "10639  neutral             Well sensitive is important, pick him.   \n",
      "7291      fear  See? Now, thats why only the little fake men ...   \n",
      "\n",
      "                                           Audio_Path  \n",
      "3615    datasets/raw/MELD/train/audio\\dia412_utt4.wav  \n",
      "5105   datasets/raw/MELD/train/audio\\dia571_utt15.wav  \n",
      "4270    datasets/raw/MELD/train/audio\\dia482_utt2.wav  \n",
      "10639    datasets/raw/MELD/train/audio\\dia74_utt2.wav  \n",
      "7291   datasets/raw/MELD/train/audio\\dia809_utt15.wav  \n",
      "Sample data saved for manual inspection.\n"
     ]
    }
   ],
   "source": [
    "# Randomly sample some data rows\n",
    "sampled_data = data.sample(5)\n",
    "print(\"Sampled data for manual inspection:\")\n",
    "print(sampled_data[['Emotion', 'Utterance', 'Audio_Path']])\n",
    "\n",
    "# Save the sample for external review\n",
    "sampled_data.to_csv('datasets/metadata/quality_checks/manual_spot_check_sample.csv', index=False)\n",
    "print(\"Sample data saved for manual inspection.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
