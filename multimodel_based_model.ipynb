{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset shape: (11839, 35)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load text features\n",
    "text_data = pd.read_csv('datasets/processed/meld_features_updated.csv')\n",
    "\n",
    "# Load audio features\n",
    "audio_data = pd.read_csv('datasets/processed/meld_audio_features.csv')\n",
    "\n",
    "# Merge text and audio features\n",
    "merged_data = pd.merge(text_data, audio_data, on=['Dialogue_ID', 'Utterance_ID'], suffixes=('_text', '_audio'))\n",
    "print(f\"Merged dataset shape: {merged_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 8287\n",
      "Validation set size: 1776\n",
      "Test set size: 1776\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features and labels\n",
    "X_text = merged_data['Clean_Utterance']\n",
    "X_audio = merged_data[[col for col in merged_data.columns if col.startswith('MFCC') or col in ['Average_Pitch', 'Average_Energy']]]\n",
    "y = merged_data['Emotion_text']  # Use the correct column for labels\n",
    "\n",
    "# Split data\n",
    "X_text_train, X_text_temp, X_audio_train, X_audio_temp, y_train, y_temp = train_test_split(\n",
    "    X_text, X_audio, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "X_text_val, X_text_test, X_audio_val, X_audio_test, y_val, y_test = train_test_split(\n",
    "    X_text_temp, X_audio_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_text_train)}\")\n",
    "print(f\"Validation set size: {len(X_text_val)}\")\n",
    "print(f\"Test set size: {len(X_text_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text TF-IDF features shape: (8287, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Fill NaN values in 'Clean_Utterance' with an empty string\n",
    "X_text_train = X_text_train.fillna('')\n",
    "X_text_val = X_text_val.fillna('')\n",
    "X_text_test = X_text_test.fillna('')\n",
    "\n",
    "# Text: TF-IDF vectorization\n",
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_text_train_tfidf = tfidf.fit_transform(X_text_train)\n",
    "X_text_val_tfidf = tfidf.transform(X_text_val)\n",
    "X_text_test_tfidf = tfidf.transform(X_text_test)\n",
    "\n",
    "print(f\"Text TF-IDF features shape: {X_text_train_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio features normalized. Shape: (8287, 208)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "# Function to flatten and handle audio features\n",
    "def flatten_audio_features(df, columns):\n",
    "    flat_features = []\n",
    "    for _, row in df.iterrows():\n",
    "        combined_features = []\n",
    "        for col in columns:\n",
    "            value = row[col]\n",
    "            if isinstance(value, str):  # Convert string to array\n",
    "                features = np.array(ast.literal_eval(value))\n",
    "            elif isinstance(value, (list, np.ndarray)):  # Already a list or array\n",
    "                features = np.array(value)\n",
    "            else:  # Handle missing or invalid data\n",
    "                features = np.zeros(13)  # Default size of MFCC features\n",
    "            combined_features.extend(features)  # Flatten into a single list\n",
    "        flat_features.append(combined_features)\n",
    "    return np.array(flat_features)\n",
    "\n",
    "# Define MFCC and other audio columns\n",
    "audio_columns = [col for col in X_audio_train.columns if col.startswith('MFCC')] + ['Average_Pitch', 'Average_Energy']\n",
    "\n",
    "# Flatten audio features for train, validation, and test sets\n",
    "X_audio_train_flat = flatten_audio_features(X_audio_train, audio_columns)\n",
    "X_audio_val_flat = flatten_audio_features(X_audio_val, audio_columns)\n",
    "X_audio_test_flat = flatten_audio_features(X_audio_test, audio_columns)\n",
    "\n",
    "# Normalize flattened features\n",
    "scaler = StandardScaler()\n",
    "X_audio_train_scaled = scaler.fit_transform(X_audio_train_flat)\n",
    "X_audio_val_scaled = scaler.transform(X_audio_val_flat)\n",
    "X_audio_test_scaled = scaler.transform(X_audio_test_flat)\n",
    "\n",
    "print(f\"Audio features normalized. Shape: {X_audio_train_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined features shape: (8287, 5208)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# Combine text and audio features\n",
    "X_train_combined = hstack([X_text_train_tfidf, X_audio_train_scaled])\n",
    "X_val_combined = hstack([X_text_val_tfidf, X_audio_val_scaled])\n",
    "X_test_combined = hstack([X_text_test_tfidf, X_audio_test_scaled])\n",
    "\n",
    "print(f\"Combined features shape: {X_train_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model trained on multimodal features!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and train model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train_combined, y_train)\n",
    "print(\"Logistic Regression model trained on multimodal features!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multimodal Logistic Regression Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.29      0.09      0.14       205\n",
      "     disgust       0.00      0.00      0.00        49\n",
      "        fear       0.00      0.00      0.00        48\n",
      "         joy       0.42      0.19      0.27       308\n",
      "     neutral       0.52      0.91      0.66       840\n",
      "     sadness       0.47      0.06      0.11       130\n",
      "    surprise       0.47      0.19      0.27       196\n",
      "\n",
      "    accuracy                           0.50      1776\n",
      "   macro avg       0.31      0.21      0.21      1776\n",
      "weighted avg       0.44      0.50      0.41      1776\n",
      "\n",
      "Validation Accuracy: 0.5023\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Validate model\n",
    "y_val_pred = model.predict(X_val_combined)\n",
    "print(\"\\nMultimodal Logistic Regression Validation Results:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.14      0.03      0.05       205\n",
      "     disgust       0.00      0.00      0.00        49\n",
      "        fear       0.00      0.00      0.00        48\n",
      "         joy       0.28      0.10      0.14       308\n",
      "     neutral       0.49      0.86      0.62       840\n",
      "     sadness       0.14      0.04      0.06       130\n",
      "    surprise       0.31      0.14      0.19       196\n",
      "\n",
      "    accuracy                           0.45      1776\n",
      "   macro avg       0.19      0.17      0.15      1776\n",
      "weighted avg       0.34      0.45      0.35      1776\n",
      "\n",
      "Validation Accuracy: 0.4465\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_combined, y_train)\n",
    "\n",
    "# Validate the model\n",
    "y_val_pred_rf = rf_model.predict(X_val_combined)\n",
    "print(\"\\nRandom Forest Validation Results:\")\n",
    "print(classification_report(y_val, y_val_pred_rf))\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred_rf):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded classes: ['anger' 'disgust' 'fear' 'joy' 'neutral' 'sadness' 'surprise']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Display encoded classes\n",
    "print(\"Encoded classes:\", label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rajt8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:25:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.19      0.06      0.09       205\n",
      "     disgust       0.00      0.00      0.00        49\n",
      "        fear       0.00      0.00      0.00        48\n",
      "         joy       0.38      0.13      0.20       308\n",
      "     neutral       0.50      0.89      0.64       840\n",
      "     sadness       0.15      0.03      0.05       130\n",
      "    surprise       0.46      0.19      0.27       196\n",
      "\n",
      "    accuracy                           0.47      1776\n",
      "   macro avg       0.24      0.19      0.18      1776\n",
      "weighted avg       0.39      0.47      0.38      1776\n",
      "\n",
      "Validation Accuracy: 0.4735\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Train an XGBoost model\n",
    "xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_model.fit(X_train_combined, y_train_encoded)\n",
    "\n",
    "# Validate the model\n",
    "y_val_pred_xgb = xgb_model.predict(X_val_combined)\n",
    "\n",
    "# Decode predictions back to original labels\n",
    "y_val_pred_decoded = label_encoder.inverse_transform(y_val_pred_xgb)\n",
    "\n",
    "# Validation results\n",
    "print(\"\\nXGBoost Validation Results:\")\n",
    "print(classification_report(y_val, y_val_pred_decoded))\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred_decoded):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.32      0.12      0.18       205\n",
      "     disgust       0.20      0.02      0.04        49\n",
      "        fear       0.00      0.00      0.00        48\n",
      "         joy       0.40      0.17      0.23       309\n",
      "     neutral       0.51      0.87      0.65       839\n",
      "     sadness       0.44      0.11      0.17       131\n",
      "    surprise       0.49      0.22      0.30       195\n",
      "\n",
      "    accuracy                           0.49      1776\n",
      "   macro avg       0.34      0.22      0.22      1776\n",
      "weighted avg       0.44      0.49      0.41      1776\n",
      "\n",
      "Test Accuracy: 0.4882\n"
     ]
    }
   ],
   "source": [
    "# Test set evaluation\n",
    "y_test_pred_xgb = xgb_model.predict(X_test_combined)\n",
    "\n",
    "# Decode predictions back to original labels\n",
    "y_test_pred_decoded = label_encoder.inverse_transform(y_test_pred_xgb)\n",
    "\n",
    "print(\"\\nXGBoost Test Results:\")\n",
    "print(classification_report(y_test, y_test_pred_decoded))\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred_decoded):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced training set size: 27426\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Combine text and audio features for SMOTE\n",
    "X_train_dense = np.hstack([X_text_train_tfidf.toarray(), X_audio_train_scaled])\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_dense, y_train)\n",
    "\n",
    "print(f\"Balanced training set size: {X_train_balanced.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced Logistic Regression Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.20      0.23      0.22       205\n",
      "     disgust       0.06      0.12      0.08        49\n",
      "        fear       0.06      0.12      0.09        48\n",
      "         joy       0.32      0.34      0.33       308\n",
      "     neutral       0.62      0.44      0.51       840\n",
      "     sadness       0.19      0.25      0.21       130\n",
      "    surprise       0.25      0.32      0.28       196\n",
      "\n",
      "    accuracy                           0.35      1776\n",
      "   macro avg       0.24      0.26      0.25      1776\n",
      "weighted avg       0.42      0.35      0.38      1776\n",
      "\n",
      "Validation Accuracy: 0.3536\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression on balanced data\n",
    "balanced_lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "balanced_lr_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Validate the model\n",
    "X_val_dense = np.hstack([X_text_val_tfidf.toarray(), X_audio_val_scaled])\n",
    "y_val_pred_balanced_lr = balanced_lr_model.predict(X_val_dense)\n",
    "\n",
    "print(\"\\nBalanced Logistic Regression Validation Results:\")\n",
    "print(classification_report(y_val, y_val_pred_balanced_lr))\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred_balanced_lr):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rajt8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\rajt8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\rajt8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1, 'solver': 'lbfgs'}\n",
      "Best validation score: 0.4988547326665624\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['lbfgs', 'saga']\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "grid = GridSearchCV(LogisticRegression(max_iter=1000, random_state=42), param_grid, cv=3, scoring='accuracy')\n",
    "grid.fit(X_train_combined, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid.best_params_}\")\n",
    "print(f\"Best validation score: {grid.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rajt8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\generic.py:484: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\rajt8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\generic.py:341: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\rajt8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\generic.py:341: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model and tokenizer loaded!\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "print(\"BERT model and tokenizer loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT embeddings generated!\n"
     ]
    }
   ],
   "source": [
    "def get_bert_embeddings(texts):\n",
    "    \"\"\"\n",
    "    Generate BERT embeddings for a list of texts.\n",
    "    :param texts: List of text strings.\n",
    "    :return: BERT embeddings as a NumPy array.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        # Tokenize text and convert to input IDs\n",
    "        inputs = bert_tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "        \n",
    "        # Generate embeddings using BERT\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(**inputs)\n",
    "            # Use the [CLS] token embedding as the sentence embedding\n",
    "            cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "        \n",
    "        embeddings.append(cls_embedding)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Generate BERT embeddings for train, validation, and test text\n",
    "X_text_train_bert = get_bert_embeddings(X_text_train)\n",
    "X_text_val_bert = get_bert_embeddings(X_text_val)\n",
    "X_text_test_bert = get_bert_embeddings(X_text_test)\n",
    "\n",
    "print(\"BERT embeddings generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined features shape with BERT: (8287, 976)\n"
     ]
    }
   ],
   "source": [
    "# Combine BERT embeddings with audio features\n",
    "X_train_combined_bert = np.hstack([X_text_train_bert, X_audio_train_scaled])\n",
    "X_val_combined_bert = np.hstack([X_text_val_bert, X_audio_val_scaled])\n",
    "X_test_combined_bert = np.hstack([X_text_test_bert, X_audio_test_scaled])\n",
    "\n",
    "print(f\"Combined features shape with BERT: {X_train_combined_bert.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BERT + Audio Logistic Regression Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.20      0.12      0.15       205\n",
      "     disgust       0.10      0.04      0.06        49\n",
      "        fear       0.06      0.02      0.03        48\n",
      "         joy       0.36      0.23      0.28       308\n",
      "     neutral       0.52      0.78      0.62       840\n",
      "     sadness       0.13      0.06      0.08       130\n",
      "    surprise       0.31      0.17      0.22       196\n",
      "\n",
      "    accuracy                           0.45      1776\n",
      "   macro avg       0.24      0.20      0.21      1776\n",
      "weighted avg       0.38      0.45      0.39      1776\n",
      "\n",
      "Validation Accuracy: 0.4459\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train Logistic Regression\n",
    "bert_lr_model = LogisticRegression(max_iter=5000, random_state=42)\n",
    "bert_lr_model.fit(X_train_combined_bert, y_train)\n",
    "\n",
    "# Validate the model\n",
    "y_val_pred_bert = bert_lr_model.predict(X_val_combined_bert)\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(\"\\nBERT + Audio Logistic Regression Validation Results:\")\n",
    "print(classification_report(y_val, y_val_pred_bert))\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred_bert):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "# Load the processed dataset\n",
    "data_path = 'datasets/processed/meld_features_updated.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "print(\"Dataset loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing audio files: 0\n",
      "Empty DataFrame\n",
      "Columns: [Dialogue_ID, Utterance_ID]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Define the audio directory path\n",
    "audio_dir = 'datasets/raw/MELD/train/audio/'\n",
    "\n",
    "# Generate full paths for audio files\n",
    "data['Audio_Path'] = data.apply(lambda row: os.path.join(audio_dir, f\"dia{row['Dialogue_ID']}_utt{row['Utterance_ID']}.wav\"), axis=1)\n",
    "\n",
    "# Check for missing files\n",
    "missing_files = data[~data['Audio_Path'].apply(os.path.exists)]\n",
    "print(f\"Missing audio files: {len(missing_files)}\")\n",
    "print(missing_files[['Dialogue_ID', 'Utterance_ID']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in the dataset: Index(['Dialogue_ID', 'Utterance_ID', 'Emotion', 'Word_Count', 'Char_Count',\n",
      "       'Sentiment_Polarity', 'Audio_Duration', 'MFCCs', 'Utterance',\n",
      "       'Clean_Utterance', 'Audio_Path', 'Aligned_Audio'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Available columns in the dataset:\", data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sr No.', 'Utterance', 'Speaker', 'Emotion', 'Sentiment', 'Dialogue_ID',\n",
      "       'Utterance_ID', 'Season', 'Episode', 'StartTime', 'EndTime'],\n",
      "      dtype='object')\n",
      "Updated columns: Index(['Dialogue_ID', 'Utterance_ID', 'Emotion', 'Word_Count', 'Char_Count',\n",
      "       'Sentiment_Polarity', 'Audio_Duration', 'MFCCs', 'Utterance',\n",
      "       'Clean_Utterance', 'Audio_Path', 'Aligned_Audio', 'StartTime',\n",
      "       'EndTime'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load the original dataset with timestamps\n",
    "timestamps_df = pd.read_csv('datasets/raw/MELD/train/train_sent_emo.csv')\n",
    "\n",
    "# Check available columns to confirm timestamp presence\n",
    "print(timestamps_df.columns)\n",
    "\n",
    "# Merge based on Dialogue_ID and Utterance_ID\n",
    "data = data.merge(\n",
    "    timestamps_df[['Dialogue_ID', 'Utterance_ID', 'StartTime', 'EndTime']],\n",
    "    on=['Dialogue_ID', 'Utterance_ID'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Verify if timestamps are added\n",
    "print(\"Updated columns:\", data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add placeholder values (e.g., 0 and 2 seconds)\n",
    "data['StartTime'] = 0.0  # Assuming start at 0 seconds\n",
    "data['EndTime'] = data['Audio_Duration']  # Assuming full duration for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text-to-audio alignment complete.\n"
     ]
    }
   ],
   "source": [
    "def align_text_with_audio(row):\n",
    "    try:\n",
    "        audio_path = row['Audio_Path']\n",
    "        start_time = row['StartTime']\n",
    "        end_time = row['EndTime']\n",
    "\n",
    "        # Load the audio file\n",
    "        audio, sr = librosa.load(audio_path, sr=16000)\n",
    "\n",
    "        # Convert timestamps to samples\n",
    "        start_sample = int(float(start_time) * sr)\n",
    "        end_sample = int(float(end_time) * sr)\n",
    "\n",
    "        # Extract the aligned audio segment\n",
    "        aligned_audio = audio[start_sample:end_sample]\n",
    "\n",
    "        return aligned_audio\n",
    "    except Exception as e:\n",
    "        print(f\"Error aligning audio for {audio_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Apply the alignment function\n",
    "data['Aligned_Audio'] = data.apply(align_text_with_audio, axis=1)\n",
    "print(\"Text-to-audio alignment complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rajt8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1365\n",
      "  warnings.warn(\n",
      "c:\\Users\\rajt8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prosodic feature extraction complete and dataset saved!\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "def extract_prosodic_features(aligned_audio, sr=16000):\n",
    "    try:\n",
    "        # Extract pitch (F0) and energy\n",
    "        pitches, magnitudes = librosa.piptrack(y=aligned_audio, sr=sr)\n",
    "\n",
    "        # Get the mean pitch and energy values\n",
    "        avg_pitch = np.mean(pitches[pitches > 0]) if np.any(pitches > 0) else 0\n",
    "        avg_energy = np.mean(magnitudes) if np.any(magnitudes) else 0\n",
    "\n",
    "        return avg_pitch, avg_energy\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting prosodic features: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Apply the prosodic feature extraction\n",
    "data[['Average_Pitch', 'Average_Energy']] = data['Aligned_Audio'].apply(lambda x: pd.Series(extract_prosodic_features(x) if x is not None else (None, None)))\n",
    "\n",
    "# Save updated dataset with prosodic features\n",
    "data.to_csv('datasets/processed/meld_multimodal_features.csv', index=False)\n",
    "\n",
    "print(\"Prosodic feature extraction complete and dataset saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text and Audio datasets loaded successfully!\n",
      "Text Data Shape: (11839, 10)\n",
      "Audio Data Shape: (9989, 27)\n",
      "\n",
      "Text Data Columns: Index(['Dialogue_ID', 'Utterance_ID', 'Emotion', 'Word_Count', 'Char_Count',\n",
      "       'Sentiment_Polarity', 'Audio_Duration', 'MFCCs', 'Utterance',\n",
      "       'Clean_Utterance'],\n",
      "      dtype='object')\n",
      "\n",
      "Audio Data Columns: Index(['Sr No.', 'Utterance', 'Speaker', 'Emotion', 'Sentiment', 'Dialogue_ID',\n",
      "       'Utterance_ID', 'Season', 'Episode', 'StartTime', 'EndTime',\n",
      "       'Audio_Path', 'MFCC_0', 'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4',\n",
      "       'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10', 'MFCC_11',\n",
      "       'MFCC_12', 'Average_Pitch', 'Average_Energy'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths to the processed text and audio features\n",
    "text_features_path = 'datasets/processed/meld_features_updated.csv'\n",
    "audio_features_path = 'datasets/processed/meld_audio_features.csv'\n",
    "\n",
    "# Load text and audio data\n",
    "text_data = pd.read_csv(text_features_path)\n",
    "audio_data = pd.read_csv(audio_features_path)\n",
    "\n",
    "print(\"Text and Audio datasets loaded successfully!\")\n",
    "print(f\"Text Data Shape: {text_data.shape}\")\n",
    "print(f\"Audio Data Shape: {audio_data.shape}\")\n",
    "\n",
    "# Inspect columns to confirm compatibility\n",
    "print(\"\\nText Data Columns:\", text_data.columns)\n",
    "print(\"\\nAudio Data Columns:\", audio_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multimodal feature dataset created successfully!\n",
      "Multimodal Data Shape: (11839, 24)\n",
      "Sample rows:\n",
      "   Dialogue_ID  Utterance_ID   Emotion  Word_Count  Char_Count  \\\n",
      "0            0             0   neutral           9          56   \n",
      "1            0             0   sadness           7          30   \n",
      "2            0             0  surprise           5          30   \n",
      "3            0             1   neutral           4          19   \n",
      "4            0             1     anger          13          64   \n",
      "\n",
      "   Sentiment_Polarity                                          Utterance  \\\n",
      "0              0.0000  also I was the point person on my companys tr...   \n",
      "1             -0.4201  also I was the point person on my companys tr...   \n",
      "2              0.0000  also I was the point person on my companys tr...   \n",
      "3              0.0000                   You mustve had your hands full.   \n",
      "4              0.2244                   You mustve had your hands full.   \n",
      "\n",
      "                                     Clean_Utterance  \\\n",
      "0  also point person companys transition kl-5 gr...   \n",
      "1  also point person companys transition kl-5 gr...   \n",
      "2  also point person companys transition kl-5 gr...   \n",
      "3                                 mustve hands full   \n",
      "4                                 mustve hands full   \n",
      "\n",
      "                                    Audio_Path      MFCC_0  ...    MFCC_5  \\\n",
      "0  datasets/raw/MELD/train/audio\\dia0_utt0.wav -200.794083  ...  3.984977   \n",
      "1  datasets/raw/MELD/train/audio\\dia0_utt0.wav -200.794083  ...  3.984977   \n",
      "2  datasets/raw/MELD/train/audio\\dia0_utt0.wav -200.794083  ...  3.984977   \n",
      "3  datasets/raw/MELD/train/audio\\dia0_utt1.wav -223.965424  ...  4.394009   \n",
      "4  datasets/raw/MELD/train/audio\\dia0_utt1.wav -223.965424  ...  4.394009   \n",
      "\n",
      "      MFCC_6    MFCC_7    MFCC_8    MFCC_9   MFCC_10   MFCC_11    MFCC_12  \\\n",
      "0  -9.637240 -5.651867  1.541530 -2.522050 -4.042772  1.512699 -12.226409   \n",
      "1  -9.637240 -5.651867  1.541530 -2.522050 -4.042772  1.512699 -12.226409   \n",
      "2  -9.637240 -5.651867  1.541530 -2.522050 -4.042772  1.512699 -12.226409   \n",
      "3 -23.162081  0.994070 -8.777248 -0.107319 -3.860114  1.586484  -3.319449   \n",
      "4 -23.162081  0.994070 -8.777248 -0.107319 -3.860114  1.586484  -3.319449   \n",
      "\n",
      "   Average_Pitch  Average_Energy  \n",
      "0    1775.459229        0.087053  \n",
      "1    1775.459229        0.087053  \n",
      "2    1775.459229        0.087053  \n",
      "3    1548.180786        0.073942  \n",
      "4    1548.180786        0.073942  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Select relevant columns from both datasets\n",
    "text_data_selected = text_data[['Dialogue_ID', 'Utterance_ID', 'Emotion', 'Word_Count', 'Char_Count',\n",
    "                                'Sentiment_Polarity', 'Utterance', 'Clean_Utterance']]\n",
    "audio_data_selected = audio_data[['Dialogue_ID', 'Utterance_ID', 'Audio_Path', 'MFCC_0', 'MFCC_1', 'MFCC_2',\n",
    "                                  'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9',\n",
    "                                  'MFCC_10', 'MFCC_11', 'MFCC_12', 'Average_Pitch', 'Average_Energy']]\n",
    "\n",
    "# Merge datasets on 'Dialogue_ID' and 'Utterance_ID'\n",
    "multimodal_data = pd.merge(text_data_selected, audio_data_selected, on=['Dialogue_ID', 'Utterance_ID'], how='inner')\n",
    "\n",
    "# Save the merged dataset\n",
    "multimodal_data.to_csv('datasets/processed/multimodal_features.csv', index=False)\n",
    "\n",
    "print(\"Multimodal feature dataset created successfully!\")\n",
    "print(f\"Multimodal Data Shape: {multimodal_data.shape}\")\n",
    "print(\"Sample rows:\")\n",
    "print(multimodal_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature fusion completed successfully!\n",
      "Fused feature matrix shape: (11839, 5015)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Replace missing values in the 'Clean_Utterance' column\n",
    "multimodal_data['Clean_Utterance'].fillna(\"\", inplace=True)\n",
    "\n",
    "# Extract the text and audio features\n",
    "X_text = multimodal_data['Clean_Utterance'].values\n",
    "X_audio = multimodal_data[['MFCC_0', 'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', \n",
    "                          'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', \n",
    "                          'MFCC_10', 'MFCC_11', 'MFCC_12', 'Average_Pitch', 'Average_Energy']].values\n",
    "\n",
    "# Convert text data to TF-IDF features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_text_tfidf = tfidf_vectorizer.fit_transform(X_text).toarray()\n",
    "\n",
    "# Standardize audio features\n",
    "scaler = StandardScaler()\n",
    "X_audio_scaled = scaler.fit_transform(X_audio)\n",
    "\n",
    "# Concatenate text and audio features\n",
    "X_fused = np.concatenate((X_text_tfidf, X_audio_scaled), axis=1)\n",
    "\n",
    "# Save the fused features for future use\n",
    "np.save('datasets/processed/fused_features.npy', X_fused)\n",
    "\n",
    "print(\"Feature fusion completed successfully!\")\n",
    "print(f\"Fused feature matrix shape: {X_fused.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fused dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the saved fused dataset\n",
    "fused_features = pd.read_csv('datasets/processed/meld_multimodal_features.csv')\n",
    "print(\"Fused dataset loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared for model training!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Remove the target label from features\n",
    "X_fused = fused_features.drop(columns=['Emotion'])  # Remove target column\n",
    "y_fused = fused_features['Emotion']  # Target labels\n",
    "\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_fused_encoded = label_encoder.fit_transform(y_fused)\n",
    "\n",
    "print(\"Data prepared for model training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 8287\n",
      "Validation set size: 1776\n",
      "Test set size: 1776\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "X_train_fused, X_temp, y_train_fused, y_temp = train_test_split(\n",
    "    X_fused, y_fused, test_size=0.3, stratify=y_fused, random_state=42\n",
    ")\n",
    "\n",
    "X_val_fused, X_test_fused, y_val_fused, y_test_fused = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train_fused.shape[0]}\")\n",
    "print(f\"Validation set size: {X_val_fused.shape[0]}\")\n",
    "print(f\"Test set size: {X_test_fused.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: Index(['Dialogue_ID', 'Utterance_ID', 'Word_Count', 'Char_Count',\n",
      "       'Sentiment_Polarity', 'Audio_Duration', 'Utterance', 'Clean_Utterance',\n",
      "       'Audio_Path', 'Aligned_Audio', 'StartTime', 'EndTime', 'Average_Pitch',\n",
      "       'Average_Energy', 'MFCC_0', 'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4',\n",
      "       'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10', 'MFCC_11',\n",
      "       'MFCC_12'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Available columns:\", X_fused.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature scaling completed successfully!\n",
      "Training data shape: (8287, 19)\n",
      "Validation data shape: (1776, 19)\n",
      "Test data shape: (1776, 19)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Selecting only numerical feature columns for scaling\n",
    "numeric_columns = ['Word_Count', 'Char_Count', 'Sentiment_Polarity', \n",
    "                   'Audio_Duration', 'Average_Pitch', 'Average_Energy'] + \\\n",
    "                  [f'MFCC_{i}' for i in range(13)]\n",
    "\n",
    "X_fused_numeric = X_fused[numeric_columns]\n",
    "\n",
    "# Standardize features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_fused_scaled = scaler.fit_transform(X_fused_numeric)\n",
    "\n",
    "# Split the dataset back into train, validation, and test sets\n",
    "X_train_fused, X_val_fused, X_test_fused = X_fused_scaled[:len(y_train_fused)], \\\n",
    "                                          X_fused_scaled[len(y_train_fused):len(y_train_fused) + len(y_val_fused)], \\\n",
    "                                          X_fused_scaled[len(y_train_fused) + len(y_val_fused):]\n",
    "\n",
    "print(\"Feature scaling completed successfully!\")\n",
    "print(f\"Training data shape: {X_train_fused.shape}\")\n",
    "print(f\"Validation data shape: {X_val_fused.shape}\")\n",
    "print(f\"Test data shape: {X_test_fused.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.4730\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00       205\n",
      "     disgust       0.00      0.00      0.00        49\n",
      "        fear       0.00      0.00      0.00        48\n",
      "         joy       0.00      0.00      0.00       308\n",
      "     neutral       0.47      1.00      0.64       840\n",
      "     sadness       0.00      0.00      0.00       130\n",
      "    surprise       0.00      0.00      0.00       196\n",
      "\n",
      "    accuracy                           0.47      1776\n",
      "   macro avg       0.07      0.14      0.09      1776\n",
      "weighted avg       0.22      0.47      0.30      1776\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rajt8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\rajt8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\rajt8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "logistic_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "logistic_model.fit(X_train_fused, y_train_fused)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = logistic_model.predict(X_val_fused)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_val_fused, y_val_pred)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Classification report for detailed evaluation\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val_fused, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after SMOTE: Counter({'surprise': 3918, 'joy': 3918, 'neutral': 3918, 'anger': 3918, 'sadness': 3918, 'fear': 3918, 'disgust': 3918})\n",
      "\n",
      "Logistic Regression with SMOTE Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.09      0.08      0.08       205\n",
      "     disgust       0.03      0.24      0.05        49\n",
      "        fear       0.03      0.23      0.05        48\n",
      "         joy       0.19      0.08      0.12       308\n",
      "     neutral       0.55      0.10      0.17       840\n",
      "     sadness       0.07      0.17      0.10       130\n",
      "    surprise       0.10      0.09      0.09       196\n",
      "\n",
      "    accuracy                           0.11      1776\n",
      "   macro avg       0.15      0.14      0.10      1776\n",
      "weighted avg       0.32      0.11      0.13      1776\n",
      "\n",
      "Validation Accuracy: 0.1070\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to training data\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_fused, y_train_fused)\n",
    "\n",
    "# Check class distribution after SMOTE\n",
    "print(\"Class distribution after SMOTE:\", Counter(y_train_balanced))\n",
    "\n",
    "# Retrain the logistic regression model with balanced data\n",
    "logistic_model_balanced = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logistic_model_balanced.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred_balanced = logistic_model_balanced.predict(X_val_fused)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nLogistic Regression with SMOTE Validation Results:\")\n",
    "print(classification_report(y_val_fused, y_val_pred_balanced))\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val_fused, y_val_pred_balanced):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM...\n",
      "\n",
      "SVM Best Parameters: {'C': 10, 'kernel': 'rbf'}\n",
      "SVM Validation Accuracy: 0.2095\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.12      0.20      0.15       205\n",
      "     disgust       0.03      0.06      0.04        49\n",
      "        fear       0.02      0.04      0.03        48\n",
      "         joy       0.17      0.17      0.17       308\n",
      "     neutral       0.52      0.27      0.36       840\n",
      "     sadness       0.07      0.12      0.08       130\n",
      "    surprise       0.12      0.15      0.13       196\n",
      "\n",
      "    accuracy                           0.21      1776\n",
      "   macro avg       0.15      0.14      0.14      1776\n",
      "weighted avg       0.31      0.21      0.24      1776\n",
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Random Forest Best Parameters: {'max_depth': 20, 'n_estimators': 200}\n",
      "Random Forest Validation Accuracy: 0.4324\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.08      0.01      0.02       205\n",
      "     disgust       0.00      0.00      0.00        49\n",
      "        fear       0.00      0.00      0.00        48\n",
      "         joy       0.18      0.04      0.06       308\n",
      "     neutral       0.47      0.89      0.62       840\n",
      "     sadness       0.00      0.00      0.00       130\n",
      "    surprise       0.10      0.03      0.04       196\n",
      "\n",
      "    accuracy                           0.43      1776\n",
      "   macro avg       0.12      0.14      0.11      1776\n",
      "weighted avg       0.28      0.43      0.31      1776\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rajt8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [13:16:09] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "XGBoost Validation Accuracy: 0.4730\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00       205\n",
      "     disgust       0.00      0.00      0.00        49\n",
      "        fear       0.00      0.00      0.00        48\n",
      "         joy       0.00      0.00      0.00       308\n",
      "     neutral       0.47      1.00      0.64       840\n",
      "     sadness       0.00      0.00      0.00       130\n",
      "    surprise       0.00      0.00      0.00       196\n",
      "\n",
      "    accuracy                           0.47      1776\n",
      "   macro avg       0.07      0.14      0.09      1776\n",
      "weighted avg       0.22      0.47      0.30      1776\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rajt8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\rajt8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\rajt8\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Encode target labels to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_fused_encoded = label_encoder.fit_transform(y_train_fused)\n",
    "y_val_fused_encoded = label_encoder.transform(y_val_fused)\n",
    "\n",
    "# Define the models and hyperparameters for tuning\n",
    "models = {\n",
    "    'SVM': SVC(class_weight='balanced', probability=True, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'SVM': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "    'Random Forest': {'n_estimators': [100, 200], 'max_depth': [None, 10, 20]},\n",
    "    'XGBoost': {'learning_rate': [0.01, 0.1], 'max_depth': [3, 5, 7], 'n_estimators': [100, 200]}\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    grid_search = GridSearchCV(model, param_grid[model_name], cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train_fused, y_train_fused_encoded)\n",
    "    \n",
    "    # Get best model and evaluate\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_models[model_name] = best_model\n",
    "    \n",
    "    y_val_pred = best_model.predict(X_val_fused)\n",
    "    \n",
    "    # Decode predicted labels back to original class names\n",
    "    y_val_pred_decoded = label_encoder.inverse_transform(y_val_pred)\n",
    "    \n",
    "    print(f\"\\n{model_name} Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"{model_name} Validation Accuracy: {accuracy_score(y_val_fused, y_val_pred_decoded):.4f}\")\n",
    "    print(classification_report(y_val_fused, y_val_pred_decoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to work more on it !!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
